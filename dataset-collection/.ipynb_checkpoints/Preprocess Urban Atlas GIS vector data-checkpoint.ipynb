{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel\n",
    "\n",
    "rc = ipyparallel.Client()\n",
    "all_engines = rc[:]\n",
    "lbv = rc.load_balanced_view()\n",
    "\n",
    "print len(all_engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# numeric packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# filesystem and OS\n",
    "import sys, os, time\n",
    "import glob\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "# compression\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "import copy\n",
    "\n",
    "# geo stuff\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# widgets and interaction\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# these magics ensure that external modules that are modified are also automatically reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# path to shapefiles\n",
    "\n",
    "shapefiles_path = \"/home/data/urban-atlas/shapefiles/\"\n",
    "\n",
    "shapefiles = glob.glob(\"%s/*/*/*.shp\"%shapefiles_path)\n",
    "shapefiles = {\" \".join(f.split(\"/\")[-1].split(\"_\")[1:]).replace(\".shp\",\"\"):f for f in shapefiles}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# path to save data\n",
    "\n",
    "outPath = \"/home/data/urban-atlas/extracted-data\"\n",
    "\n",
    "if not os.path.exists(outPath):\n",
    "    os.makedirs(outPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "classes = '''Agricultural + Semi-natural areas + Wetlands\n",
    "Airports\n",
    "Construction sites\n",
    "Continuous Urban Fabric (S.L. > 80%)\n",
    "Discontinuous Dense Urban Fabric (S.L. : 50% -  80%)\n",
    "Discontinuous Low Density Urban Fabric (S.L. : 10% - 30%)\n",
    "Discontinuous Medium Density Urban Fabric (S.L. : 30% - 50%)\n",
    "Discontinuous Very Low Density Urban Fabric (S.L. < 10%)\n",
    "Fast transit roads and associated land\n",
    "Forests\n",
    "Green urban areas\n",
    "Industrial, commercial, public, military and private units\n",
    "Isolated Structures\n",
    "Land without current use\n",
    "Mineral extraction and dump sites\n",
    "Other roads and associated land\n",
    "Port areas\n",
    "Railways and associated land\n",
    "Sports and leisure facilities\n",
    "Water bodies'''.split(\"\\n\")\n",
    "\n",
    "class2label = {c:i for i,c in enumerate(classes)}\n",
    "label2class = {i:c for i,c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct ground truth rasters for validation\n",
    "\n",
    "Also compute useful stats within windows of L=25,30,50km around the city center:\n",
    "* percentage of polygons per class \n",
    "* percentage of classified area per class\n",
    "* percentage of classified area vs total area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "# satellite imagery modules\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/adalbert/nbserver/satellite-image-tools/satimage-processing/\")\n",
    "import satimg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "def load_shapefile(shapefile):\n",
    "    # read in shapefile\n",
    "    try:\n",
    "        gdf = gpd.GeoDataFrame.from_file(shapefile)\n",
    "    except:\n",
    "        print \"--> %s: error reading file!\"%shapefile\n",
    "        return None, None\n",
    "\n",
    "    city = shapefile.split(\"/\")[-1].split(\"_\")[1]\n",
    "    gdf.columns = [c.upper() if c != \"geometry\" else c for c in gdf.columns ]\n",
    "    if 'SHAPE_AREA' not in gdf.columns:\n",
    "        gdf['SHAPE_AREA'] = gdf['geometry'].apply(lambda p: p.area)\n",
    "    if 'SHAPE_LEN' not in gdf.columns:\n",
    "        gdf['SHAPE_LEN'] = gdf['geometry'].apply(lambda p: p.length)\n",
    "        \n",
    "    # convert area & length to km\n",
    "    gdf['SHAPE_AREA'] = gdf['SHAPE_AREA'] / 1.0e6 # convert to km^2\n",
    "    gdf['SHAPE_LEN']  = gdf['SHAPE_LEN'] / 1.0e3 # convert to km\n",
    "\n",
    "    classes = gdf['ITEM'].unique()\n",
    "    print \"%s: %d polygons | %d land use classes\" % (city, len(gdf), len(classes))\n",
    "\n",
    "    # read in projection file associated with shapefile\n",
    "    prjfile = shapefile.replace(\".shp\", \".prj\")\n",
    "    prj = satimg.read_prj(prjfile)   \n",
    "    \n",
    "    # change coordinate system from northing/easting to lonlat\n",
    "    targetcrs = {u'ellps': u'WGS84', u'datum': u'WGS84', u'proj': u'longlat'}\n",
    "    gdf.to_crs(crs=targetcrs, inplace=True)\n",
    "\n",
    "    return gdf, prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"bucuresti\"\n",
    "\n",
    "# read in shapefile\n",
    "shapefile = shapefiles[city]\n",
    "\n",
    "gdf, prj = load_shapefile(shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['ITEM'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "def get_bounds(gdf):\n",
    "    bounds = np.array(gdf['geometry'].apply(lambda p: list(p.bounds)).values.tolist())\n",
    "    xmin = bounds[:,[0,2]].min()\n",
    "    xmax = bounds[:,[0,2]].max()\n",
    "    ymin = bounds[:,[1,3]].min()\n",
    "    ymax = bounds[:,[1,3]].max()\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def compute_stats(gdf, prj=\"\"):\n",
    "    ''' \n",
    "    Statistics about the polygons in the geo data frame.\n",
    "    '''\n",
    "    lonmin, latmin, lonmax, latmax = get_bounds(gdf)\n",
    "    xmin, ymin = satimg.lonlat2xy((lonmin, latmin), prj=prj)\n",
    "    xmax, ymax = satimg.lonlat2xy((lonmax, latmax), prj=prj)\n",
    "\n",
    "    box_area =  (xmax-xmin) / 1.0e3 * (ymax-ymin) / 1.0e3\n",
    "    L = np.sqrt((xmax-xmin)**2 + (ymax-ymin)**2) / 1.0e3 / np.sqrt(2)\n",
    "    classified_area = gdf['SHAPE_AREA'].sum()\n",
    "    frac_classified = classified_area/box_area\n",
    "\n",
    "    print \"Spatial extent: %2.2f km.\" % L\n",
    "    print \"Land use classified area: %2.3f km^2 (%2.2f of total area covered within bounds %2.3f km^2)\"%(classified_area, frac_classified, box_area)\n",
    "    \n",
    "    return L, frac_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, frac_classified = compute_stats(gdf, prj=prj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def get_city_center(shapefile):\n",
    "    geolocator = Nominatim()\n",
    "    country_code = shapefile.split(\"/\")[-1].split(\"_\")[0][:2]\n",
    "    city = \" \".join(shapefile.split(\"/\")[-1].split(\"_\")[1:]).split(\".\")[0]\n",
    "    location = geolocator.geocode(city + \",\" + country_code)\n",
    "    if location is None:\n",
    "        return None, None\n",
    "    latlon = (location.latitude, location.longitude)\n",
    "    return latlon, country_code\n",
    "\n",
    "\n",
    "def filter_gdf_by_polygon(gdf, polygon):\n",
    "    spatial_index = gdf.sindex\n",
    "    possible_matches_index = list(spatial_index.intersection(polygon.bounds))\n",
    "    possible_matches = gdf.iloc[possible_matches_index]\n",
    "    precise_matches = possible_matches[possible_matches.intersects(polygon)]\n",
    "    return precise_matches\n",
    "\n",
    "\n",
    "def filter_gdf_by_centered_window(gdf0, center=None, window=None):\n",
    "    if window is None:\n",
    "        return gdf0\n",
    "    else:\n",
    "        latmin, lonmin, latmax, lonmax = satimg.bounding_box_at_location(center, window)\n",
    "        pbox = Polygon([(lonmin,latmin), (lonmax,latmin), (lonmax,latmax), (lonmin,latmax)])\n",
    "        return filter_gdf_by_polygon(gdf0, pbox)\n",
    "    \n",
    "    \n",
    "def construct_class_raster(gdf, bbox, grid_size=(100,100)):\n",
    "    grid_size_lon, grid_size_lat = grid_size\n",
    "    latmin_grid, lonmin_grid, latmax_grid, lonmax_grid = bbox\n",
    "    latv = np.linspace(latmin_grid, latmax_grid, grid_size_lat+1)\n",
    "    lonv = np.linspace(lonmin_grid, lonmax_grid, grid_size_lon+1)\n",
    "    \n",
    "    raster = np.zeros((grid_size_lon, grid_size_lat, len(classes)))\n",
    "    locations = []\n",
    "    for i in range(len(lonv)-1):\n",
    "        clear_output(wait=True)\n",
    "        print \"%d / %d\"%(i, len(lonv)-1)\n",
    "        for j in range(len(latv)-1):\n",
    "            cell_poly = Polygon([(lonv[i],latv[j]), (lonv[i+1],latv[j]), \\\n",
    "                                 (lonv[i+1],latv[j+1]), (lonv[i],latv[j+1])])\n",
    "            gdf_frame = filter_gdf_by_polygon(gdf, cell_poly)\n",
    "            if len(gdf_frame) == 0:\n",
    "                continue\n",
    "            areas_per_class = gdf_frame.groupby(\"ITEM\")\\\n",
    "                                .apply(lambda x: x.intersection(cell_poly)\\\n",
    "                                       .apply(lambda y: y.area*(6400**2)).sum())\n",
    "            classified_area = areas_per_class.sum()\n",
    "            if classified_area > 0:\n",
    "                areas_per_class = areas_per_class / float(classified_area) \n",
    "                raster[i,j,:] = [areas_per_class[label2class[k]] if label2class[k] in areas_per_class\\\n",
    "                                 else 0 for k in range(len(classes))]  \n",
    "                # also save sampling locations\n",
    "                # only if we can get ground truth label for the cell\n",
    "                cell_class = areas_per_class.argmax()\n",
    "                loc = (i, j, \n",
    "                       cell_poly.centroid.xy[0][0], \n",
    "                       cell_poly.centroid.xy[1][0], \n",
    "                       cell_class)\n",
    "                locations.append(loc)\n",
    "    \n",
    "    locations = pd.DataFrame(locations, \\\n",
    "                    columns=[\"grid-i\", \"grid-j\", \"lon\", \"lat\", \"class\"])\n",
    "    return raster, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "grid_cell = 100\n",
    "grid_size = (grid_cell, grid_cell)\n",
    "window_km_vec = [25, 30, 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fn_generate_stats(shapefile):\n",
    "    city = \" \".join(shapefile.split(\"/\")[-1].split(\"_\")[1:]).replace(\".shp\",\"\")\n",
    "    \n",
    "    # weird issues with several cities, skip\n",
    "    if city in [\"limoges\", \"linz\"]:\n",
    "        return \"Error for city %s\"%city\n",
    "    \n",
    "    print \"Processing %s\"%city\n",
    "    \n",
    "    savedir = \"%s/%s/\"%(outPath, city)\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "\n",
    "    if len([x for x in os.listdir(savedir) if 'raster' in x])==3:\n",
    "        return \"Already processed!\"\n",
    "   \n",
    "    gdf, prj = load_shapefile(shapefile)\n",
    "    if gdf is None:\n",
    "        return \"Error reading shapefile %s\"%shapefile\n",
    "        \n",
    "    city_center, country_code = get_city_center(shapefile)\n",
    "    lonmin, latmin, lonmax, latmax = get_bounds(gdf)\n",
    "    bounds_gdf = Polygon([(lonmin,latmin), (lonmax,latmin), (lonmax,latmax), (lonmin,latmax)])\n",
    "\n",
    "    if city_center is None:\n",
    "        city_center = ((latmin+latmax)/2.0, (lonmin+lonmax)/2.0)\n",
    "\n",
    "    # there's some weird issue with the shapefile for Graz\n",
    "    # lat and lon are inverted?\n",
    "    if city in [\"graz\"]: #not bounds_gdf.contains(Point(city_center[::-1])):\n",
    "        city_center = ((latmin+latmax)/2.0, (lonmin+lonmax)/2.0)\n",
    "        gdf['geometry'] = gdf['geometry'].apply(\\\n",
    "                lambda p: Polygon((lon,lat) \\\n",
    "                    for (lon,lat) in zip(p.exterior.coords.xy[1], p.exterior.coords.xy[0])))\n",
    "    \n",
    "    # compute spatial extent of city and fraction of land classified\n",
    "    L, frac_classified = compute_stats(gdf, prj=prj)\n",
    "    df = pd.DataFrame([L, frac_classified], \\\n",
    "                      index=[\"spatial extent\", \"pct land classified\"]).T\n",
    "    df.to_csv(\"%s/basic_stats.csv\"%savedir)\n",
    "        \n",
    "    for window_km in window_km_vec:\n",
    "        window = (window_km, window_km)\n",
    "        gdf_window = filter_gdf_by_centered_window(gdf, center=city_center, window=window)\n",
    "        \n",
    "        # compute stats\n",
    "        class_coverage_by_area = gdf_window.groupby(\"ITEM\").apply(\\\n",
    "                                lambda x: x[\"SHAPE_AREA\"].sum())/float(window[0]*window[1])\n",
    "        class_coverage_by_poly= gdf_window.groupby(\"ITEM\").apply(len)/ gdf.groupby(\"ITEM\").apply(len)\n",
    "        class_coverage_by_area_classified = gdf_window.groupby(\"ITEM\").apply(\\\n",
    "                                                lambda x: x['SHAPE_AREA'].sum()) / gdf_window['SHAPE_AREA'].sum()\n",
    "    \n",
    "        # format and save stats\n",
    "        stats_df = pd.concat([class_coverage_by_area, class_coverage_by_poly, class_coverage_by_area_classified], axis=1)\n",
    "        stats_df.columns = [\"pct area\", \"pct polygons\", \"pct classified area\"]\n",
    "        stats_df['window km'] = window_km\n",
    "        stats_df = stats_df.ix[classes]\n",
    "        stats_df.to_csv(\"%s/stats_class_window_%d.csv\"%(savedir,window_km))\n",
    "        \n",
    "        # compute raster for given window size\n",
    "        bbox = satimg.bounding_box_at_location(city_center, window)\n",
    "        raster, locations_df = construct_class_raster(gdf_window, bbox, grid_size=grid_size)\n",
    "        np.savez_compressed(\"%s/ground_truth_class_raster_%d.npz\"%(savedir,window_km), raster)\n",
    "        locations_df.to_csv(\"%s/sample_locations_raster_%d.csv\"%(savedir,window_km))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_center, country_code = get_city_center(shapefile)\n",
    "# lonmin, latmin, lonmax, latmax = get_bounds(gdf)\n",
    "# bounds_gdf = Polygon([(lonmin,latmin), (lonmax,latmin), (lonmax,latmax), (lonmin,latmax)])\n",
    "# window = (window_km_vec[0], window_km_vec[0])\n",
    "# gdf_window = filter_gdf_by_centered_window(gdf, center=city_center, window=window)\n",
    "# bbox = satimg.bounding_box_at_location(city_center, window)\n",
    "# raster, locations_df = construct_class_raster(gdf_window, bbox, grid_size=grid_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = lbv.map_async(fn_generate_stats, shapefiles.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on all ~300 cities in Urban Atlas\n",
    "\n",
    "Use computation results from the separate notebook \"Urban Atlas - generate sampling locations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics on classified area and spatial extent of the city\n",
    "\n",
    "* What is the total area covered by the land use classification? \n",
    "* How does it break down into the different classes?\n",
    "* What is the spatial extent scale of the city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath = \"/home/data/urban-atlas/extracted-data/\"\n",
    "\n",
    "stats_files = glob.glob(\"%s/*/basic_stats.csv\"%datapath)\n",
    "\n",
    "basic_stats_df = pd.concat([pd.read_csv(f) for f in stats_files]).drop(\"Unnamed: 0\", 1)\n",
    "basic_stats_df.index = [f.split(\"/\")[-2] for f in stats_files]\n",
    "basic_stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 1})\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "g = sns.jointplot(x=\"spatial extent\", y=\"pct land classified\", data=basic_stats_df, \\\n",
    "                  kind=\"kde\", color=\"k\", ylim=(0.2,0.9), xlim=(1,120), stat_func=None)\n",
    "g.plot_joint(plt.scatter, c=\"w\", s=30, linewidth=1, marker=\"+\")\n",
    "g.ax_joint.collections[0].set_alpha(0)\n",
    "g.set_axis_labels(\"city spatial extent $L$ [km]\", \"land classified $\\%$\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
