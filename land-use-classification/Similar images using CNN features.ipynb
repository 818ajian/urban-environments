{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import several packages that will be used throughout\n",
    "\n",
    "# numeric packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# filesystem and OS\n",
    "import sys, os, time\n",
    "import glob\n",
    "import gzip\n",
    "import cPickle as pickle\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# these magics ensure that external modules that are modified are also automatically reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../keras-utils/\")\n",
    "import keras_utils as ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workdir = \"/home/adalbert/nbserver/tf-workspace/urban-atlas-experiments/\"\n",
    "\n",
    "if not os.path.exists(workdir):\n",
    "\tos.makedirs(workdir)\n",
    "    \n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load classes actually used in analysis\n",
    "\n",
    "with gzip.open(\"classes.pickle.gz\", \"r\") as f:\n",
    "    dict_classes = pickle.load(f)\n",
    "\n",
    "class2label = dict_classes[\"class2label\"]\n",
    "label2class = dict_classes[\"label2class\"]\n",
    "classes = np.sort(class2label.keys()).tolist()\n",
    "\n",
    "N_CLASSES = len(classes)\n",
    "\n",
    "# original colormap from Urban Atlas\n",
    "class_colors_rgb = [\n",
    "    ('Continuous Urban Fabric (S.L. > 80%)', (102, 48, 52)),\n",
    "    ('Discontinuous Dense Urban Fabric (S.L. : 50% -  80%)', (167, 40, 49)),\n",
    "    ('Discontinuous Medium Density Urban Fabric (S.L. : 30% - 50%)', (218, 96, 75)),\n",
    "    ('Discontinuous Low Density Urban Fabric (S.L. : 10% - 30%)', (229, 144, 117)),\n",
    "    ('Discontinuous Very Low Density Urban Fabric (S.L. < 10%)', (249, 171, 174)),\n",
    "    ('Isolated Structures', (184, 117, 98)),\n",
    "    ('Industrial, commercial, public, military and private units', (179, 99, 149)),\n",
    "    ('Fast transit roads and associated land', (221, 110, 47)),\n",
    "    ('Other roads and associated land', (236, 174, 128)),\n",
    "    ('Railways and associated land', (119, 119, 118)),\n",
    "    ('Port areas', (215, 187, 208)), \n",
    "    ('Airports', (218, 198, 199)),\n",
    "    ('Mineral extraction and dump sites', (135, 100, 83)),\n",
    "    ('Construction sites', (193, 161, 113)),\n",
    "    ('Land without current use', (134, 88, 79)),\n",
    "    ('Green urban areas', (161, 185, 59)),\n",
    "    ('Sports and leisure facilities', (214, 227, 140)), \n",
    "    ('Agricultural + Semi-natural areas + Wetlands', (255, 250, 182)),\n",
    "    ('Forests', (25, 101, 64)),\n",
    "    ('Water bodies', (189, 225, 237)),\n",
    "    ('Not Classified', (203, 204, 203))\n",
    "]\n",
    "class_colors_all = {c:(np.array(v)/float(255)).tolist() + [1.0] for c,v in class_colors_rgb}\n",
    "\n",
    "consolidate_classes = {\n",
    "    \"Continuous Urban Fabric (S.L. > 80%)\":\"High Density Urban Fabric\",\n",
    "     \"Discontinuous Dense Urban Fabric (S.L. : 50% -  80%)\":\"High Density Urban Fabric\",\n",
    "     \"Discontinuous Medium Density Urban Fabric (S.L. : 30% - 50%)\":\"Medium Density Urban Fabric\",\n",
    "     \"Discontinuous Low Density Urban Fabric (S.L. : 10% - 30%)\":\"Low Density Urban Fabric\",\n",
    "     \"Discontinuous Very Low Density Urban Fabric (S.L. < 10%)\":\"Low Density Urban Fabric\"\n",
    "}\n",
    "classes_consolidate = {v:[x for x in consolidate_classes.keys() if consolidate_classes[x] == v] \\\n",
    "                       for k,v in consolidate_classes.iteritems()}\n",
    "\n",
    "label_colors = {i:class_colors_all[classes_consolidate[label2class[i]][0] \\\n",
    "                                   if label2class[i] in classes_consolidate else label2class[i]] \\\n",
    "                for i in range(N_CLASSES)}\n",
    "class_colors = {c:v for c,v in zip(classes, label_colors.values())}\n",
    "\n",
    "cmap = matplotlib.colors.ListedColormap([class_colors[c] for c in classes])\n",
    "\n",
    "sns.palplot(sns.color_palette([v for c, v in label_colors.iteritems()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = [\"athina\", \"berlin\", \"budapest\", \"roma\", \"barcelona\", \"madrid\"]\n",
    "\n",
    "palette_cities = dict(zip(cities, sns.color_palette(\"hls\", len(cities))))\n",
    "\n",
    "cmap_city = matplotlib.colors.ListedColormap(palette_cities.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained model and extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file_res = \"./resnet50-urbanatlas-berlin+bucuresti+dublin+tallinn+barcelona-0.70-checkpoint.h5\"\n",
    "model_file_vgg = \"./vgg16-urbanatlas-berlin+bucuresti+dublin+tallinn+barcelona-0.68-checkpoint.h5\"\n",
    "\n",
    "# with tf.device('/cpu:0'):\n",
    "# load model and weights\n",
    "\n",
    "# load & compile models\n",
    "from keras.optimizers import Adadelta\n",
    "\n",
    "model_res = keras.models.load_model(model_file_res)\n",
    "model_res.compile(loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy'],\\\n",
    "              optimizer=Adadelta(lr=0.01))\n",
    "\n",
    "model_vgg = keras.models.load_model(model_file_cgg)\n",
    "model_vgg.compile(loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy'],\\\n",
    "              optimizer=Adadelta(lr=0.01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load & preprocess data, use model to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract activations for a batch of images\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def get_activations(model, layer_id, X_batch):\n",
    "    layer_dict = {l.name:l for l in model.layers}\n",
    "    if type(layer_id) is str:\n",
    "        feat_layer = layer_dict[layer_id]\n",
    "    else:\n",
    "        feat_layer = model.layers[layer_id]\n",
    "    fn_activations = K.function([model.layers[0].input, K.learning_phase()], \\\n",
    "                                 [feat_layer.output,])\n",
    "    activations = fn_activations([X_batch,0])[0]\n",
    "    return activations\n",
    "\n",
    "\n",
    "# extract features \n",
    "\n",
    "def extract_features(model, sources, batch_size=100, layer=None):\n",
    "    n_chunks = int(np.ceil(len(sources) / batch_size))\n",
    "    chunks = np.array_split(sources, n_chunks)\n",
    "    features = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        clear_output(wait=True)\n",
    "        print \"Chunk %d / %d\" % (idx, n_chunks)\n",
    "        batch = []\n",
    "        for s in chunk:\n",
    "            filename, label = s\n",
    "            img = ku.load_and_preprocess(filename) * 1.0/255.0\n",
    "            batch.append(img)\n",
    "        batch = np.array(batch)\n",
    "        if layer is None:\n",
    "            pred = model.predict(batch)\n",
    "        else:\n",
    "            pred = get_activations(model, layer, batch)\n",
    "        features.append(pred)\n",
    "    features = np.vstack(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_df = pd.read_csv(\"./athina+berlin+bucuresti+tallinn+barcelona+dublin-test.csv\")\n",
    "files_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_df = files_df.groupby(\"city\").apply(lambda df: ku.balanced_df(df, nrows=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources = zip(files_df['filename'].values, files_df['class'].values)\n",
    "features = extract_features(model, sources, layer=\"dense_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.vstack(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez_compressed(\"features_batch.npz\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with np.load(\"features_batch.npz\") as data:\n",
    "    print data.keys()\n",
    "    features = data['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE visualization using extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/DmitryUlyanov/Multicore-TSNE\n",
    "\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "tsne = TSNE(n_jobs=32, perplexity=20)\n",
    "feats_tsne = tsne.fit_transform(features.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "def labeled_scatterplot(x, labels, palette=None, ax=None, add_text=True):\n",
    "    \n",
    "    classes = np.unique(labels)\n",
    "    class_dict = {c:i for i,c in enumerate(classes)}\n",
    "    n_clust = len(classes)    \n",
    "    colors = [palette[l] for l in labels]\n",
    "\n",
    "    # We create a scatter plot.\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(8, 8))\n",
    "        ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=colors)\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    if add_text:\n",
    "        # We add the labels for each class.\n",
    "        txts = []\n",
    "        for k,c in enumerate(classes):\n",
    "            # Position of each label.\n",
    "            xtext, ytext = np.median(x[labels == c, :], axis=0)\n",
    "            txt = ax.text(xtext, ytext, str(c), fontsize=24)\n",
    "            txt.set_path_effects([\n",
    "                PathEffects.Stroke(linewidth=5, foreground=palette[c]),\n",
    "                PathEffects.Normal()])\n",
    "            txts.append(txt)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import abbreviate\n",
    "abbr = abbreviate.Abbreviate()\n",
    "\n",
    "def split_str(s):\n",
    "    s = re.sub('[^A-Za-z0-9% ]+', '', s)\n",
    "    words = s.split(\" \")\n",
    "    words = [abbr.abbreviate(w, target_len=10).capitalize() for w in words]\n",
    "    if len(words)==1:\n",
    "        return s #+ \"\\n\"\n",
    "    if len(words)>4:\n",
    "        words = words[:3] + [words[-1]]\n",
    "    else:\n",
    "        words = words[:4]\n",
    "    return \" \".join(words[:(len(words)/2)]) + \"\\n\" + \" \".join(words[(len(words)/2):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# embeddings plot over cities\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 1})\n",
    "\n",
    "plt.figure(figsize=(30,8))\n",
    "width_ratios = [10 for _ in range(len(cities)/2)] + [1] + [10 for _ in range(len(cities)/2)] + [1]\n",
    "gs = matplotlib.gridspec.GridSpec(2, len(cities)/2+1, width_ratios=width_ratios, wspace=0.025, hspace=0.05)\n",
    "ax_cbar = plt.subplot(gs[:,-1])\n",
    "\n",
    "myticks = range(N_CLASSES) + [10]\n",
    "myticklabels = [split_str(c) for c in classes] + [\"Not Classified\"]\n",
    "myticklabels = [\"%d: %s\"%(i,split_str(c)) for i,c in enumerate(classes)] + [\"Not Classified\"]\n",
    "\n",
    "cb3 = matplotlib.colorbar.ColorbarBase(ax_cbar, cmap=cmap,\n",
    "                                boundaries=myticks,\n",
    "                                ticks=myticks,\n",
    "                                orientation=\"vertical\",\n",
    "                                ticklocation=\"right\",\n",
    "                                spacing='uniform')\n",
    "cb3.set_label('Urban Environments Classes')\n",
    "cb3.ax.set_yticks(myticks)\n",
    "cb3.ax.set_yticklabels(myticklabels, fontsize=12)\n",
    "\n",
    "for n,c in enumerate(cities):\n",
    "    i = n / 3; j = n % 3\n",
    "    ax = plt.subplot(gs[i,j])\n",
    "    idx = files_df['city']==c\n",
    "    labels = files_df[idx]['class'].apply(lambda x: class2label[x])\n",
    "    ax = labeled_scatterplot(feats_tsne[idx,:], labels, ax=ax, palette=label_colors)\n",
    "    ax.set_title(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# embeddings plot over classes\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 1})\n",
    "\n",
    "plt.figure(figsize=(30,8))\n",
    "width_ratios = [10 for _ in range(len(classes)/2)] + [1] + [10 for _ in range(len(classes)/2)] + [1]\n",
    "gs = matplotlib.gridspec.GridSpec(2, len(classes)/2+1, width_ratios=width_ratios, wspace=0.025, hspace=0.15)\n",
    "ax_cbar = plt.subplot(gs[:,-1])\n",
    "\n",
    "myticks = range(len(cities))\n",
    "myticklabels = cities\n",
    "\n",
    "cb3 = matplotlib.colorbar.ColorbarBase(ax_cbar, cmap=cmap_city,\n",
    "                                boundaries=myticks + [len(cities)],\n",
    "                                ticks=myticks,\n",
    "                                orientation=\"vertical\",\n",
    "                                ticklocation=\"right\",\n",
    "                                spacing='uniform')\n",
    "cb3.ax.set_yticks(myticks)\n",
    "cb3.ax.set_yticklabels(myticklabels, fontsize=12)\n",
    "city_label = {c:i for i,c in enumerate(cities)}\n",
    "\n",
    "for n,c in enumerate(classes):\n",
    "    i = n / 5; j = n % 5\n",
    "    ax = plt.subplot(gs[i,j])\n",
    "    idx = files_df['class']==c\n",
    "    labels = files_df[idx]['city'].values #.apply(lambda x: city_label[x])\n",
    "    ax = labeled_scatterplot(feats_tsne[idx,:], labels, ax=ax, palette=palette_cities, add_text=False)\n",
    "    ax.set_title(split_str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "palette_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labeled_scatterplot(feats_tsne, labels, palette=label_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# \"Similar\" urban environments within and across two example cities\n",
    "\n",
    "We would like to study how \"similar\" different classes of urban environments are across two example cities. For this:\n",
    "* get samples for rasters for the two cities (at most 2 $\\times$ 10,000)\n",
    "* construct KD tree with the raster samples\n",
    "* pick 100 samples per class for each city\n",
    "* for each sample, find the top 10 neighbors from among all samples, record the city, and class of each neighbor\n",
    "* compute statistics per each class (% neighbors of same city/class, different city/class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "from sklearn.neighbors import KDTree, BallTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = [\"barcelona\", \"berlin\"]\n",
    "N_SAMPLES = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = KDTree(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, neighbors = tree.query(features[1,:], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
